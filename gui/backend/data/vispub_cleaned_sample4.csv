Conference,Year,Title,DOI,Link,FirstPage,LastPage,PaperType,Abstract,AuthorNames-Deduped,AuthorNames,AuthorAffiliation,InternalReferences,AuthorKeywords,AminerCitationCount_04-2020,XploreCitationCount - 2021-02,PubsCited,Award,Doc_ID,doc_index
InfoVis,2018,Visualizing Ranges over Time on Mobile Phones: A Task-Based Crowdsourced Evaluation,10.1109/TVCG.2018.2865234,http://dx.doi.org/10.1109/TVCG.2018.2865234,619,629,J,"In the first crowdsourced visualization experiment conducted exclusively on mobile phones, we compare approaches to visualizing ranges over time on small displays. People routinely consume such data via a mobile phone, from temperatures in weather forecasting apps to sleep and blood pressure readings in personal health apps. However, we lack guidance on how to effectively visualize ranges on small displays in the context of different value retrieval and comparison tasks, or with respect to different data characteristics such as periodicity, seasonality, or the cardinality of ranges. Central to our experiment is a comparison between two ways to lay out ranges: a more conventional linear layout strikes a balance between quantitative and chronological scale resolution, while a less conventional radial layout emphasizes the cyclicality of time and may prioritize discrimination between values at its periphery. With results from 87 crowd workers, we found that while participants completed tasks more quickly with linear layouts than with radial ones, there were few differences in terms of error rate between layout conditions. We also found that participants performed similarly with both layouts in tasks that involved comparing superimposed observed and average ranges.",Matthew Brehmer;Bongshin Lee;Petra Isenberg;Eun Kyoung Choe,Matthew Brehmer;Bongshin Lee;Petra Isenberg;Eun Kyoung Choe,"Microsoft Research;Microsoft Research;Inria;The University of Maryland, College Park",10.1109/TVCG.2011.185;10.1109/TVCG.2013.124;10.1109/TVCG.2010.209;10.1109/TVCG.2010.162;10.1109/VAST.2007.4388994,"Evaluation,graphical perception,mobile phones,range visualization,crowdsourcing",4.0,4.0,54.0,,559,560
VAST,2012,Incorporating GOMS analysis into the design of an EEG data visual analysis tool,10.1109/VAST.2012.6400542,http://dx.doi.org/10.1109/VAST.2012.6400542,223,224,M,"In this paper, we present a case study where we incorporate GOMS (Goals, Operators, Methods, and Selectors) [2] task analysis into the design process of a visual analysis tool. We performed GOMS analysis on an Electroencephalography (EEG) analyst's current data analysis strategy to identify important user tasks and unnecessary user actions in his current workflow. We then designed an EEG data visual analysis tool based on the GOMS analysis result. Evaluation results show that the tool we have developed, EEGVis, allows the user to analyze EEG data with reduced subjective cognitive load, faster speed and increased confidence in the analysis quality. The positive evaluation results suggest that our design process demonstrates an effective application of GOMS analysis to discover opportunities for designing better tools to support the user's visual analysis process.",Hua Guo;Diem Tran;David H. Laidlaw,Hua Guo;Diem Tran;David H. Laidlaw,Department of Computer Science Brown University;Department of Computer Science Brown University;Department of Computer Science Brown University,,,2.0,1.0,7.0,,379,380
Vis,1997,Collision detection for volumetric objects,10.1109/VISUAL.1997.663851,http://dx.doi.org/10.1109/VISUAL.1997.663851,27,34,C,"We propose a probability model for the handling of complicated interactions between volumetric objects. In our model each volume is associated with a ""probability map"" that assigns a ""surface crossing"" probability to each space point according to local volume properties. The interaction between two volumes is then described by finding the intersecting regions between the volumes, and calculating the ""collision probabilities"" at each intersecting point from the surface crossing probabilities. To enable fast and efficient calculations, we introduce the concept of a distance map and develop two hierarchical collision detection algorithms, taking advantage of the uniform structure of volumetric datasets.",Taosong He;Arie E. Kaufman,Taosong He;A. Kaufman,"AT&T Bell Labs., Naperville, IL, USA",10.1109/VISUAL.1996.568108;10.1109/VISUAL.1994.346340,"volume visualization, volume rendering, virtual reality, volume graphics, volumetric collision, collision probability, surface crossing probability, distance map, octree, sphere tree",51.0,12.0,14.0,,2328,2329
InfoVis,2012,Spatial Text Visualization Using Automatic Typographic Maps,10.1109/TVCG.2012.264,http://dx.doi.org/10.1109/TVCG.2012.264,2556,2564,J,"We present a method for automatically building typographic maps that merge text and spatial data into a visual representation where text alone forms the graphical features. We further show how to use this approach to visualize spatial data such as traffic density, crime rate, or demographic data. The technique accepts a vector representation of a geographic map and spatializes the textual labels in the space onto polylines and polygons based on user-defined visual attributes and constraints. Our sample implementation runs as a Web service, spatializing shape files from the OpenStreetMap project into typographic maps for any region.",Shehzad Afzal;Ross Maciejewski;Yun Jang;Niklas Elmqvist;David S. Ebert,Shehzad Afzal;Ross Maciejewski;Yun Jang;Niklas Elmqvist;David S. Ebert,Purdue University;Arizona State University;Sejong University;Purdue University;Purdue University,10.1109/VAST.2010.5652931;10.1109/TVCG.2010.191;10.1109/TVCG.2010.175;10.1109/INFVIS.1995.528686;10.1109/VISUAL.1997.663912;10.1109/VISUAL.2000.885694;10.1109/INFVIS.2005.1532131;10.1109/INFVIS.2002.1173144;10.1109/TVCG.2008.165;10.1109/TVCG.2010.194;10.1109/TVCG.2009.171;10.1109/INFVIS.2000.885095,"Geovisualization, spatial data, text visualization, label placement",30.0,21.0,48.0,,1847,1848
Vis,2004,Pixel-exact rendering of spacetime finite element solutions,10.1109/VISUAL.2004.81,http://dx.doi.org/10.1109/VISUAL.2004.81,425,432,C,"Computational simulation of time-varying physical processes is of fundamental importance for many scientific and engineering applications. Most frequently, time-varying simulations are performed over multiple spatial grids at discrete points in time. We investigate a new approach to time-varying simulation: spacetime discontinuous Galerkin finite element methods. The result of this simulation method is a simplicial tessellation of spacetime with per-element polynomial solutions for physical quantities such as strain, stress, and velocity. To provide accurate visualizations of the resulting solutions, we have developed a method for per-pixel evaluation of solution data on the GPU. We demonstrate the importance of per-pixel rendering versus simple linear interpolation for producing high quality visualizations. We also show that our system can accommodate reasonably large datasets - spacetime meshes containing up to 20 million tetrahedra are not uncommon in this domain.",Yuan Zhou;Michael Garland;Robert Haber,Yuan Zhou;M. Garland;R. Haber,"Dept. of Comput. Sci., Illinois Univ., Urbana, IL, USA;Dept. of Comput. Sci., Illinois Univ., Urbana, IL, USA",10.1109/VISUAL.2000.885704;10.1109/VISUAL.1990.146361;10.1109/VISUAL.2003.1250354;10.1109/VISUAL.2003.1250384;10.1109/VISUAL.2003.1250386,"pixel-exact visualization, pixel shaders, spacetime finite elements, discontinuous Galerkin methods",15.0,6.0,31.0,,1225,1226
Vis,2003,Hybrid segmentation and exploration of the human lungs,10.1109/VISUAL.2003.1250370,http://dx.doi.org/10.1109/VISUAL.2003.1250370,177,184,C,"Segmentation of the tracheo-bronchial tree of the lungs is notoriously difficult. This is due to the fact that the small size of some of the anatomical structures is subject to partial volume effects. Furthermore, the limited intensity contrast between the participating materials (air, blood, and tissue) increases the segmentation of difficulties. In this paper, we propose a hybrid segmentation method which is based on a pipeline of three segmentation stages to extract the lower airways down to the seventh generation of the bronchi. User interaction is limited to the specification of a seed point inside the easily detectable trachea at the upper end of the lower airways. Similarly, the complementary vascular tree of the lungs can be segmented. Furthermore, we modified our virtual endoscopy system to visualize the vascular and airway system of the lungs along with other features, such as lung tumors.",Dirk Bartz;Dirk Mayer;Jan Fischer;Sebastian Ley;Ángel del Río;Steffi Thust;Claus Peter Heussel;Hans-Ulrich Kauczor;Wolfgang Straßer,D. Bartz;D. Mayer;J. Fischer;S. Ley;A. del Rio;S. Thust;C.P. Heussel;H.-U. Kauczor;W. Strasser,"Visual Comput. for Medicine, Eberhard-Karls-Univ. Tubingen, Germany",10.1109/VISUAL.2000.885732,"Tracheo-bronchial tree, segmentation, multi-slice CT, virtual endoscopy",52.0,26.0,17.0,,2353,2354
Vis,2001,Continuous topology simplification of planar vector fields,10.1109/VISUAL.2001.964507,http://dx.doi.org/10.1109/VISUAL.2001.964507,159,166,C,"Vector fields can present complex structural behavior, especially in turbulent computational fluid dynamics. The topological analysis of these data sets reduces the information, but one is usually still left with too many details for interpretation. In this paper, we present a simplification approach that removes pairs of critical points from the data set, based on relevance measures. In contrast to earlier methods, no grid changes are necessary, since the whole method uses small local changes of the vector values defining the vector field. An interpretation in terms of bifurcations underlines the continuous, natural flavor of the algorithm.",Xavier Tricoche;Gerik Scheuermann;Hans Hagen,X. Tricoche;G. Scheuermann;H. Hagen,"Dept. of Comput. Sci., Kaiserslautern Univ., Germany;Dept. of Comput. Sci., Kaiserslautern Univ., Germany;Dept. of Comput. Sci., Kaiserslautern Univ., Germany",10.1109/VISUAL.2000.885716;10.1109/VISUAL.1998.745318;10.1109/VISUAL.1991.175773;10.1109/VISUAL.1999.809907,"vector field topology, flow visualization, unstructured grid, simplification",92.0,55.0,10.0,,2771,2772
Vis,2001,Visualizing 2D probability distributions from EOS satellite image-derived data sets: a case study,10.1109/VISUAL.2001.964550,http://dx.doi.org/10.1109/VISUAL.2001.964550,457,460,C,"Maps of biophysical and geophysical variables using Earth Observing System (EOS) satellite image data are an important component of Earth science. These maps have a single value derived at every grid cell and standard techniques are used to visualize them. Current tools fall short, however, when it is necessary to describe a distribution of values at each grid cell. Distributions may represent a frequency of occurrence over time, frequency of occurrence from multiple runs of an ensemble forecast or possible values from an uncertainty model. We identify these ""distribution data sets"" and present a case study to visualize such 2D distributions. Distribution data sets are different from multivariate data sets in the sense that the values are for a single variable instead of multiple variables. Data for this case study consists of multiple realizations of percent forest cover, generated using a geostatistical technique that combines ground measurements and satellite imagery to model uncertainty about forest cover. We present two general approaches for analyzing and visualizing such data sets. The first is a pixel-wise analysis of the probability density functions for the 2D image while the second is an analysis of features identified within the image. Such pixel-wise and feature-wise views will give Earth scientists a more complete understanding of distribution data sets. See www.cse.ucsc.edu/research/avis/nasa is for additional information.",David L. Kao;Jennifer L. Dungan;Alex T. Pang,D. Kao;J.L. Dungan;A. Pang,"NASA Ames Res. Center, Moffett Field, CA, USA;NASA Ames Res. Center, Moffett Field, CA, USA",,"uncertainty, probability density function, geostatistics, conditional simulation, data assimilation",35.0,20.0,15.0,,1975,1976
VAST,2009,VAST 2009 challenge: An insider threat,10.1109/VAST.2009.5334454,http://dx.doi.org/10.1109/VAST.2009.5334454,,,M,"The 4th VAST Challenge centered on a cyber analytics scenario and offered three mini-challenges with datasets of badge and network traffic data, a social network including geospatial information, and security video. Teams could also enter the Grand challenge which combined all three datasets. In this paper, we summarize the dataset, the overall scenario and the questions asked in the challenges. We describe the judging process and new infrastructure developed to manage the submissions and compute accuracy measures in the social network mini challenge. We received 49 entries from 30 teams, and gave 23 different awards to a total of 16 teams.",Georges G. Grinstein;Jean Scholtz;Mark A. Whiting;Catherine Plaisant,Georges Grinstein;Jean Scholtz;Mark Whiting;Catherine Plaisant,"University of Massachusetts Lowell, USA;Pacific Northwest National Laboratory, USA;Pacific Northwest National Laboratory, USA;University of Maryland, USA",,,8.0,0.0,7.0,,818,819
Vis,2010,Fast High-Quality Volume Ray Casting with Virtual Samplings,10.1109/TVCG.2010.155,http://dx.doi.org/10.1109/TVCG.2010.155,1525,1532,J,"Volume ray-casting with a higher order reconstruction filter and/or a higher sampling rate has been adopted in direct volume rendering frameworks to provide a smooth reconstruction of the volume scalar and/or to reduce artifacts when the combined frequency of the volume and transfer function is high. While it enables high-quality volume rendering, it cannot support interactive rendering due to its high computational cost. In this paper, we propose a fast high-quality volume ray-casting algorithm which effectively increases the sampling rate. While a ray traverses the volume, intensity values are uniformly reconstructed using a high-order convolution filter. Additional samplings, referred to as virtual samplings, are carried out within a ray segment from a cubic spline curve interpolating those uniformly reconstructed intensities. These virtual samplings are performed by evaluating the polynomial function of the cubic spline curve via simple arithmetic operations. The min max blocks are refined accordingly for accurate empty space skipping in the proposed method. Experimental results demonstrate that the proposed algorithm, also exploiting fast cubic texture filtering supported by programmable GPUs, offers renderings as good as a conventional ray-casting algorithm using high-order reconstruction filtering at the same sampling rate, while delivering 2.5x to 3.3x rendering speed-up.",Byeonghun Lee;Jihye Yun;Jinwook Seo;Byonghyo Shim;Yeong-Gil Shin;Bo Hyoung Kim,Byeonghun Lee;Jihye Yun;Jinwook Seo;Byonghyo Shim;Yeong-Gil Shin;Bohyoung Kim,"Seoul National University, Seoul, Korea;Seoul National University, Seoul, Korea;Seoul National University, Seoul, Korea;Korea University, Seoul, Korea;Seoul National University, Seoul, Korea;Seoul National University, Seoul, Korea",10.1109/VISUAL.1994.346331;10.1109/VISUAL.2004.70;10.1109/VISUAL.2005.1532810;10.1109/TVCG.2009.204;10.1109/VISUAL.2003.1250384,"Direct volume rendering, GPU, high quality, curve interpolation",13.0,12.0,23.0,,1127,1128
InfoVis,2009,GeneShelf: A Web-based Visual Interface for Large Gene Expression Time-Series Data Repositories,10.1109/TVCG.2009.146,http://dx.doi.org/10.1109/TVCG.2009.146,905,912,J,"A widespread use of high-throughput gene expression analysis techniques enabled the biomedical research community to share a huge body of gene expression datasets in many public databases on the web. However, current gene expression data repositories provide static representations of the data and support limited interactions. This hinders biologists from effectively exploring shared gene expression datasets. Responding to the growing need for better interfaces to improve the utility of the public datasets, we have designed and developed a new web-based visual interface entitled GeneShelf (http://bioinformatics.cnmcresearch.org/GeneShelf). It builds upon a zoomable grid display to represent two categorical dimensions. It also incorporates an augmented timeline with expandable time points that better shows multiple data values for the focused time point by embedding bar charts. We applied GeneShelf to one of the largest microarray datasets generated to study the progression and recovery process of injuries at the spinal cord of mice and rats. We present a case study and a preliminary qualitative user study with biologists to show the utility and usability of GeneShelf.",Bo Hyoung Kim;Bongshin Lee;Susan Knoblach;Eric P. Hoffman;Jinwook Seo,Bohyoung Kim;Bongshin Lee;Susan Knoblach;Eric Hoffman;Jinwook Seo,Seoul National University;Microsoft Research;Children's National Medical Center;Children's National Medical Center;Seoul National University,,"bioinformatics visualization, augmented timeline, animation, zoomable grid, gene expression profiling",12.0,9.0,26.0,,1065,1066
SciVis,2015,AnimoAminoMiner: Exploration of Protein Tunnels and their Properties in Molecular Dynamics,10.1109/TVCG.2015.2467434,http://dx.doi.org/10.1109/TVCG.2015.2467434,747,756,J,"In this paper we propose a novel method for the interactive exploration of protein tunnels. The basic principle of our approach is that we entirely abstract from the 3D/4D space the simulated phenomenon is embedded in. A complex 3D structure and its curvature information is represented only by a straightened tunnel centerline and its width profile. This representation focuses on a key aspect of the studied geometry and frees up graphical estate to key chemical and physical properties represented by surrounding amino acids. The method shows the detailed tunnel profile and its temporal aggregation. The profile is interactively linked with a visual overview of all amino acids which are lining the tunnel over time. In this overview, each amino acid is represented by a set of colored lines depicting the spatial and temporal impact of the amino acid on the corresponding tunnel. This representation clearly shows the importance of amino acids with respect to selected criteria. It helps the biochemists to select the candidate amino acids for mutation which changes the protein function in a desired way. The AnimoAminoMiner was designed in close cooperation with domain experts. Its usefulness is documented by their feedback and a case study, which are included.",Jan Byska;Mathieu Le Muzic;M. Eduard Gröller;Ivan Viola;Barbora Kozlíková,Jan Byška;Mathieu Le Muzic;M. Eduard Gröller;Ivan Viola;Barbora Kozlíková,"Masaryk University, Czech Republic;TU Wien, Austria;TU Wien, Austria;TU Wien, Austria;Masaryk University, Czech Republic",10.1109/VISUAL.2002.1183754;10.1109/TVCG.2009.136;10.1109/TVCG.2011.259;10.1109/VISUAL.2001.964540,"Protein, tunnel, molecular dynamics, aggregation, interaction",10.0,14.0,25.0,,956,957
Vis,1991,"Cooperative, computer-aided design of scientific visualizations",10.1109/VISUAL.1991.175819,http://dx.doi.org/10.1109/VISUAL.1991.175819,306,"313, 430",C,"Partial automation of the task of designing graphical displays that effectively depict the data to be visualized through cooperative computer-aided design (CCAD) is described. This paradigm combines the strengths of manual and automated design by interspersing guiding design operations by the human user with the exploration of design alternatives by the computer. The approach is demonstrated in the context of the IVE design system, a CCAD environment for the design of scientific visualizations using a set of design rules that combine primitive visualization components in different ways. These alternatives are presented graphically to the user, who can browse through them, select the most promising visualization, and refine it manually.",Sandeep Kochhar;Mark Friedell;Mark Vincent LaPolla,S. Kochhar;M. Friedell;M. LaPolla,"Harvard Univ., Cambridge, MA, USA;Harvard Univ., Cambridge, MA, USA",,"Grammar-directed design, cooperative design and modeling, design automation, human-computer interaction, automated design of graphical displays",13.0,6.0,22.0,,1095,1096
SciVis,2020,Direct Volume Rendering with Nonparametric Models of Uncertainty,10.1109/TVCG.2020.3030394,http://dx.doi.org/10.1109/TVCG.2020.3030394,1797,1807,J,"We present a nonparametric statistical framework for the quantification, analysis, and propagation of data uncertainty in direct volume rendering (DVR). The state-of-the-art statistical DVR framework allows for preserving the transfer function (TF) of the ground truth function when visualizing uncertain data; however, the existing framework is restricted to parametric models of uncertainty. In this paper, we address the limitations of the existing DVR framework by extending the DVR framework for nonparametric distributions. We exploit the quantile interpolation technique to derive probability distributions representing uncertainty in viewing-ray sample intensities in closed form, which allows for accurate and efficient computation. We evaluate our proposed nonparametric statistical models through qualitative and quantitative comparisons with the mean-field and parametric statistical models, such as uniform and Gaussian, as well as Gaussian mixtures. In addition, we present an extension of the state-of-the-art rendering parametric framework to 2D TFs for improved DVR classifications. We show the applicability of our uncertainty quantification framework to ensemble, downsampled, and bivariate versions of scalar field datasets.",Tushar M. Athawale;Bo Ma 0002;Elham Sakhaee;Christopher R. Johnson 0001;Alireza Entezari,Tushar M. Athawale;Bo Ma;Elham Sakhaee;Chris R. Johnson;Alireza Entezari,"University of Utah, Scientific Computing & Imaging (SCI) Institute, Salt Lake City;Department of CISE at the University of FloridaGainesville;Department of CISE at the University of FloridaGainesville;University of Utah, Scientific Computing & Imaging (SCI) Institute, Salt Lake City;Department of CISE at the University of FloridaGainesville","10.1109/TVCG.2013.208,10.1109/TVCG.2018.2864505,10.1109/TVCG.2015.2467958,10.1109/VAST.2009.5332611,10.1109/TVCG.2012.227,10.1109/TVCG.2018.2864432,10.1109/TVCG.2012.227,10.1109/VISUAL.2001.964519,10.1109/VISUAL.2005.1532807,10.1109/TVCG.2007.70518,10.1109/TVCG.2014.2346455,10.1109/VISUAL.1997.663848,10.1109/TVCG.2013.143","Volumes,uncertainty,nonparametric,2D transfer function",,0.0,61.0,,3235,3236
Vis,1995,Pictorial statistics-visualization of high-dimensional statistical distributions,10.1109/VISUAL.1995.485149,http://dx.doi.org/10.1109/VISUAL.1995.485149,346,349,C,"A general framework for visualization of statistical properties of high-dimensional pattern samples and the related computational steps are introduced. These procedures are exemplified on applications in anthropometrical research (shape information in faces) but can be easily generalized to various other morphometrical questions and data sets with pattern structure, e.g., data stemming from sensor arrays. Presently, the visualization techniques illustrated concentrate on (higher) moments of first order. It is suggested, how moments of second order can be visualized by animations and how this approach can be used in the context of comparative visualization.",Andreas A. Müller,A.A. Muller,"IWSP, Gottingen Univ., Germany",,,0.0,0.0,6.0,,13,14
InfoVis,1996,Minimally-immersive interactive volumetric information visualization,10.1109/INFVIS.1996.559220,http://dx.doi.org/10.1109/INFVIS.1996.559220,66,"67, 123",M,"This paper describes a minimally immersive volumetric interactive system for information visualization. The system, SFA, uses glyph-based volume rendering, enabling more information attributes to be visualized than traditional 2D and surface-based information visualization systems. Two-handed interaction and stereoscopic viewing combine to produce a minimally immersive interactive system that enhances the user's three-dimensional perception of the information space, capitalizing on the human visual system's pre-attentive learning capabilities to quickly analyze the displayed information. The paper describes the usefulness of this system for the visualization of document similarity within a corpus of textual documents. SFA allows the three-dimensional volumetric visualization, manipulation, navigation, and analysis of multivariate, time-varying information spaces, increasing the quantity and clarity of information conveyed from the visualization as compared to traditional 2D information systems.",David S. Ebert;Chris Shaw 0002;Amen Zwa;Ethan L. Miller;D. Aaron Roberts,D.S. Ebert;C. Shaw;A. Zwa;E.L. Miller;D.A. Roberts,"Maryland Univ., Baltimore, MD, USA",,,12.0,7.0,6.0,,1040,1041
InfoVis,2020,SafetyLens: Visual Data Analysis of Functional Safety of Vehicles,10.1109/TVCG.2020.3030382,http://dx.doi.org/10.1109/TVCG.2020.3030382,1688,1697,J,"Modern automobiles have evolved from just being mechanical machines to having full-fledged electronics systems that enhance vehicle dynamics and driver experience. However, these complex hardware and software systems, if not properly designed, can experience failures that can compromise the safety of the vehicle, its occupants, and the surrounding environment. For example, a system to activate the brakes to avoid a collision saves lives when it functions properly, but could lead to tragic outcomes if the brakes were applied in a way that's inconsistent with the design. Broadly speaking, the analysis performed to minimize such risks falls into a systems engineering domain called Functional Safety. In this paper, we present SafetyLens, a visual data analysis tool to assist engineers and analysts in analyzing automotive Functional Safety datasets. SafetyLens combines techniques including network exploration and visual comparison to help analysts perform domain-specific tasks. This paper presents the design study with domain experts that resulted in the design guidelines, the tool, and user feedback.",Arpit Narechania;Ahsan Qamar;Alex Endert,Arpit Narechania;Ahsan Qamar;Alex Endert,Georgia Institute of Technology;Ford Motor Company;Georgia Institute of Technology,"10.1109/VAST.2006.261426,10.1109/TVCG.2014.2346248,10.1109/TVCG.2011.185,10.1109/TVCG.2014.2346249,10.1109/TVCG.2012.255,10.1109/TVCG.2006.166,10.1109/TVCG.2009.108","Visual data analysis,Design study,Network visualization,Functional safety,Automotive engineering",,0.0,56.0,,3208,3209
InfoVis,1998,Saying it in graphics: from intentions to visualizations,10.1109/INFVIS.1998.729564,http://dx.doi.org/10.1109/INFVIS.1998.729564,97,101,C,"The authors propose a methodology for automatically realizing communicative goals in graphics. It features a task model that mediates the communicative intent and the selection of graphical techniques. The methodology supports the following functions: isolating assertions presentable in graphics; mapping such assertions into tasks for the potential reader, and selecting graphical techniques that support those tasks. They illustrate the methodology by redesigning a textual argument into a multimedia one with the same rhetorical and content structures but employing graphics to achieve some of the intentions.",Stephan M. Kerpedjiev;Giuseppe Carenini;Nancy L. Green;Johanna D. Moore;Steven F. Roth,S. Kerpedjiev;G. Carenini;N. Green;J. Moore;S. Roth,"Carnegie Mellon Univ., Pittsburgh, PA, USA",,,21.0,3.0,11.0,,1496,1497
SciVis,2018,Objective Vortex Corelines of Finite-sized Objects in Fluid Flows,10.1109/TVCG.2018.2864828,http://dx.doi.org/10.1109/TVCG.2018.2864828,956,966,J,"Vortices are one of the most-frequently studied phenomena in fluid flows. The center of the rotating motion is called the vortex coreline and its successful detection strongly depends on the choice of the reference frame. The optimal frame moves with the center of the vortex, which incidentally makes the observed fluid flow steady and thus standard vortex coreline extractors such as Sujudi-Haimes become applicable. Recently, an objective optimization framework was proposed that determines a near-steady reference frame for tracer particles. In this paper, we extend this technique to the detection of vortex corelines of inertial particles. An inertial particle is a finite-sized object that is carried by a fluid flow. In contrast to the usual tracer particles, they do not move tangentially with the flow, since they are subject to gravity and exhibit mass-dependent inertia. Their particle state is determined by their position and own velocity, which makes the search for the optimal frame a high-dimensional problem. We demonstrate in this paper that the objective detection of an inertial vortex coreline can be reduced in 2D to a critical point search in 2D. For 3D flows, however, the vortex coreline criterion remains a parallel vectors condition in 6D. To detect the vortex corelines we propose a recursive subdivision approach that is tailored to the underlying structure of the 6D vectors. The resulting algorithm is objective, and we demonstrate the vortex coreline extraction in a number of 2D and 3D vector fields.",Tobias Günther;Holger Theisel,Tobias Günther;Holger Theisel,Computer Graphics LaboratoryETH Zürich;Visual Computing GroupUniversity of Magdeburg,10.1109/VISUAL.1991.175773;10.1109/TVCG.2015.2467200;10.1109/TVCG.2014.2346415;10.1109/TVCG.2016.2599016;10.1109/VISUAL.1997.663910;10.1109/VISUAL.1999.809896;10.1109/VISUAL.1998.745296;10.1109/TVCG.2016.2599018;10.1109/VISUAL.2005.1532851;10.1109/TVCG.2007.70545,"Vortex extraction,inertial particles,objectivity,vortex coreline",3.0,1.0,81.0,,483,484
Vis,2009,Depth-Dependent Halos: Illustrative Rendering of Dense Line Data,10.1109/TVCG.2009.138,http://dx.doi.org/10.1109/TVCG.2009.138,1299,1306,J,"We present a technique for the illustrative rendering of 3D line data at interactive frame rates. We create depth-dependent halos around lines to emphasize tight line bundles while less structured lines are de-emphasized. Moreover, the depth-dependent halos combined with depth cueing via line width attenuation increase depth perception, extending techniques from sparse line rendering to the illustrative visualization of dense line data. We demonstrate how the technique can be used, in particular, for illustrating DTI fiber tracts but also show examples from gas and fluid flow simulations and mathematics as well as describe how the technique extends to point data. We report on an informal evaluation of the illustrative DTI fiber tract visualizations with domain experts in neurosurgery and tractography who commented positively about the results and suggested a number of directions for future work.",Maarten H. Everts;Henk Bekker;Jos B. T. M. Roerdink;Tobias Isenberg 0001,Maarten H. Everts;Henk Bekker;Jos B.T.M. Roerdink;Tobias Isenberg,University of Groningen;University of Groningen;University of Groningen;University of Groningen,10.1109/VISUAL.2000.885694;10.1109/TVCG.2007.70532;10.1109/TVCG.2006.172;10.1109/VISUAL.2000.885696;10.1109/VISUAL.2005.1532778;10.1109/TVCG.2006.115;10.1109/VISUAL.2005.1532859;10.1109/TVCG.2006.197;10.1109/VISUAL.2005.1532858;10.1109/TVCG.2007.70555;10.1109/VISUAL.1996.567777;10.1109/VISUAL.2004.48,"Illustrative rendering and visualization, NPR, dense line data, DTI, black-and-white rendering, GPU technique",90.0,71.0,44.0,BP,2763,2764
